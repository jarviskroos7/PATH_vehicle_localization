{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, Embedding, Add, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "77\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y_norm</th>\n",
       "      <th>x_norm</th>\n",
       "      <th>y_norm_noise</th>\n",
       "      <th>x_norm_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43567</th>\n",
       "      <td>42.246179</td>\n",
       "      <td>-83.563086</td>\n",
       "      <td>0.786530</td>\n",
       "      <td>0.206384</td>\n",
       "      <td>0.795350</td>\n",
       "      <td>0.203490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43617</th>\n",
       "      <td>42.246167</td>\n",
       "      <td>-83.563112</td>\n",
       "      <td>0.785304</td>\n",
       "      <td>0.204631</td>\n",
       "      <td>0.787305</td>\n",
       "      <td>0.203073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43667</th>\n",
       "      <td>42.246155</td>\n",
       "      <td>-83.563137</td>\n",
       "      <td>0.784089</td>\n",
       "      <td>0.202890</td>\n",
       "      <td>0.788982</td>\n",
       "      <td>0.203170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43717</th>\n",
       "      <td>42.246143</td>\n",
       "      <td>-83.563163</td>\n",
       "      <td>0.782877</td>\n",
       "      <td>0.201164</td>\n",
       "      <td>0.794082</td>\n",
       "      <td>0.195338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43767</th>\n",
       "      <td>42.246131</td>\n",
       "      <td>-83.563188</td>\n",
       "      <td>0.781676</td>\n",
       "      <td>0.199454</td>\n",
       "      <td>0.791014</td>\n",
       "      <td>0.203958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               y          x    y_norm    x_norm  y_norm_noise  x_norm_noise\n",
       "43567  42.246179 -83.563086  0.786530  0.206384      0.795350      0.203490\n",
       "43617  42.246167 -83.563112  0.785304  0.204631      0.787305      0.203073\n",
       "43667  42.246155 -83.563137  0.784089  0.202890      0.788982      0.203170\n",
       "43717  42.246143 -83.563163  0.782877  0.201164      0.794082      0.195338\n",
       "43767  42.246131 -83.563188  0.781676  0.199454      0.791014      0.203958"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data loading\n",
    "\n",
    "with gzip.open('../data/segment_with_noise/ll_seg_gps_500_noise.pkl.gzip', 'rb') as f:\n",
    "    ll_seg_gps_noise = pickle.load(f)\n",
    "with gzip.open('../data/segment_with_noise/rl_seg_gps_500_noise.pkl.gzip', 'rb') as f:\n",
    "    rl_seg_gps_noise = pickle.load(f)\n",
    "\n",
    "with gzip.open('../data/segment_groud_truth/rl_seg_gps_gt_500.pkl.gzip', 'rb') as f:\n",
    "    ll_seg_gps_gt = pickle.load(f)\n",
    "with gzip.open('../data/segment_groud_truth/ll_seg_gps_gt_500.pkl.gzip', 'rb') as f:\n",
    "    rl_seg_gps_gt = pickle.load(f)\n",
    "\n",
    "print(len(ll_seg_gps_noise))\n",
    "print(ll_seg_gps_noise[0].shape[0])\n",
    "ll_seg_gps_noise[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79535004, 0.20348973])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll_seg_gps_noise[0][['y_norm_noise', 'x_norm_noise']].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ll = [] # sampled noisy GPS, list of lists of tuples\n",
    "# y_gps_ll = [] # sampled noisy GPS, list of lists of tuples\n",
    "y_ll = [] # unsampled groud truth GPS, list of lists of tuples\n",
    "\n",
    "for df in ll_seg_gps_noise:\n",
    "    x_ll.append(df[['y_norm_noise', 'x_norm_noise']].values)\n",
    "    # y_gps_ll.append(df[['y_norm', 'x_norm']].values)\n",
    "    # y_ll.append(list(df[['y_norm', 'x_norm']].itertuples(index=False, name=None)))\n",
    "\n",
    "for df in ll_seg_gps_gt:\n",
    "    y_ll.append(df[['y_norm', 'x_norm']].values)\n",
    "    # y_ll.append(list(df[['y_norm', 'x_norm']].itertuples(index=False, name=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 77)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 500 segment samples with length 77\n",
    "len(x_ll), len(x_ll[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 77)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_ll[0]), len(x_ll[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3822)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 500 segment samples with length 3822\n",
    "len(y_ll), len(y_ll[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.1],\n",
       "        [0.2],\n",
       "        [0.3]]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0.1, 0.2, 0.3]).reshape((1,3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 1: LSTM based seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_count = []\n",
    "y_count = []\n",
    "\n",
    "for x_seg in x_ll:\n",
    "    x_count.append(len(x_seg))\n",
    "for y_seg in y_ll:\n",
    "    y_count.append(len(y_seg))\n",
    "\n",
    "graph_df = pd.DataFrame() \n",
    "\n",
    "graph_df['sampled_noisy_gps'] = x_count\n",
    "graph_df['ground_truth_gps'] = y_count\n",
    "\n",
    "graph_df.hist(bins = 10)\n",
    "plt.xlabel('pairs of coordinates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3822, 77)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting max_y_len and max_x_len\n",
    "max_y_len = max([len(y_seg) for y_seg in y_ll])\n",
    "max_x_len = max([len(x_seg) for x_seg in x_ll])\n",
    "\n",
    "max_y_len, max_x_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1, x_val1, y_train1, y_val1 = train_test_split(\n",
    "    np.asarray(x_ll),\n",
    "    np.asarray(y_ll),\n",
    "    test_size=0.1,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 77) (450, 3822)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2, ..., 74, 75, 76],\n",
       "       [ 0,  1,  2, ..., 74, 75, 76],\n",
       "       [ 0,  1,  2, ..., 74, 75, 76],\n",
       "       ...,\n",
       "       [ 0,  1,  2, ..., 74, 75, 76],\n",
       "       [ 0,  1,  2, ..., 74, 75, 76],\n",
       "       [ 0,  1,  2, ..., 74, 75, 76]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_temp1 = np.asarray([np.arange(max_x_len) for i in np.arange(x_train1.shape[0])])\n",
    "y_train_temp1 = np.asarray([np.arange(max_y_len) for i in np.arange(y_train1.shape[0])])\n",
    "\n",
    "print(x_train_temp1.shape, y_train_temp1.shape)\n",
    "x_train_temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((450, 77, 2), (450, 77))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_train_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([450, 77, 64])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch, seq_length, embedd_length\n",
    "(Dense(64, )(x_train) + Embedding(max_x_len+1, 64, input_length=max_x_len+1)(x_train_temp)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "latent_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = Input(shape=(77,2,))\n",
    "x_h_spat = Dense(embedding_dim)(x_train)\n",
    "\n",
    "x_train_temp = Input(shape=(77,))\n",
    "x_h_temp = Embedding(max_x_len+1, embedding_dim, input_length=max_x_len+1, trainable=True)(x_train_temp)\n",
    "\n",
    "h_st = Add()([x_h_spat, x_h_temp])\n",
    "\n",
    "# Encoder\n",
    "## Encoder LSTM 1\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.2,\n",
    "                     recurrent_dropout=0.2)\n",
    "(encoder_output1, state_h1, state_c1) = encoder_lstm1(h_st)\n",
    "\n",
    "## Encoder LSTM 2\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.2,\n",
    "                     recurrent_dropout=0.2)\n",
    "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
    "\n",
    "## Encoder LSTM 3\n",
    "encoder_lstm3 = LSTM(latent_dim, return_state=True,\n",
    "                     return_sequences=True, dropout=0.2,\n",
    "                     recurrent_dropout=0.2)\n",
    "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
    "\n",
    "\n",
    "# Decoder\n",
    "y_train = Input(shape=(3822,2,))\n",
    "y_h_spat = Dense(embedding_dim)(y_train)\n",
    "\n",
    "y_train_temp = Input(shape=(3822,))\n",
    "y_h_temp = Embedding(max_y_len+1, embedding_dim, input_length=max_y_len+1, trainable=True)(y_train_temp)\n",
    "\n",
    "h_st = Add()([y_h_spat, y_h_temp])\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True,\n",
    "                    return_state=True, dropout=0.2,\n",
    "                    recurrent_dropout=0.1)\n",
    "\n",
    "(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n",
    "    decoder_lstm(h_st, initial_state=[state_h, state_c])\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(2, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model(inputs=[x_train, x_train_temp, y_train, y_train_temp], outputs=decoder_outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_41 (InputLayer)          [(None, 77, 2)]      0           []                               \n",
      "                                                                                                  \n",
      " input_42 (InputLayer)          [(None, 77)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 77, 64)       192         ['input_41[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_30 (Embedding)       (None, 77, 64)       4992        ['input_42[0][0]']               \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 77, 64)       0           ['dense_43[0][0]',               \n",
      "                                                                  'embedding_30[0][0]']           \n",
      "                                                                                                  \n",
      " input_43 (InputLayer)          [(None, 3822, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " input_44 (InputLayer)          [(None, 3822)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)                  [(None, 77, 300),    438000      ['add_15[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 3822, 64)     192         ['input_43[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_31 (Embedding)       (None, 3822, 64)     244672      ['input_44[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)                  [(None, 77, 300),    721200      ['lstm_8[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 3822, 64)     0           ['dense_44[0][0]',               \n",
      "                                                                  'embedding_31[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)                 [(None, 77, 300),    721200      ['lstm_9[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)                 [(None, 3822, 300),  438000      ['add_16[0][0]',                 \n",
      "                                 (None, 300),                     'lstm_10[0][1]',                \n",
      "                                 (None, 300)]                     'lstm_10[0][2]']                \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  (None, 3822, 2)     602         ['lstm_11[0][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,569,050\n",
      "Trainable params: 2,569,050\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(100, size=(450, 3822, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 108s 7s/step - loss: 0.6016 - accuracy: 0.9870\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 109s 7s/step - loss: 0.5929 - accuracy: 0.9807\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 108s 7s/step - loss: 0.5808 - accuracy: 0.9698\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 108s 7s/step - loss: 0.5768 - accuracy: 0.9701\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 107s 7s/step - loss: 0.5751 - accuracy: 0.9559\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 106s 7s/step - loss: 0.5723 - accuracy: 0.9639\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 106s 7s/step - loss: 0.5733 - accuracy: 0.9737\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 106s 7s/step - loss: 0.5713 - accuracy: 0.9725\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 106s 7s/step - loss: 0.5714 - accuracy: 0.9781\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 106s 7s/step - loss: 0.5712 - accuracy: 0.9809\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 105s 7s/step - loss: 0.5708 - accuracy: 0.9820\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5697 - accuracy: 0.9858\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5695 - accuracy: 0.9872\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5694 - accuracy: 0.9871\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 102s 7s/step - loss: 0.5695 - accuracy: 0.9886\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5713 - accuracy: 0.9872\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5697 - accuracy: 0.9876\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5694 - accuracy: 0.9907\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5696 - accuracy: 0.9909\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5695 - accuracy: 0.9906\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5698 - accuracy: 0.9907\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5692 - accuracy: 0.9900\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 104s 7s/step - loss: 0.5690 - accuracy: 0.9914\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 102s 7s/step - loss: 0.5716 - accuracy: 0.9902\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5707 - accuracy: 0.9863\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5709 - accuracy: 0.9919\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 103s 7s/step - loss: 0.5696 - accuracy: 0.9908\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 110s 7s/step - loss: 0.5694 - accuracy: 0.9919\n",
      "Epoch 28: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea777c0bb0>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runtime ~= 50min es at epoch = 28\n",
    "\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "model.fit(\n",
    "    [x_train1, x_train_temp1, y_train1, y_train_temp1], y_train1,\n",
    "    epochs=100, verbose='auto', callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/v1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fea207317f0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fea2571f3d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fea256ea3a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fea0457d4c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/v1')\n",
    "model = keras.models.load_model('../models/v1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('geo_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5275a7a5c7ca3fd70a65904e3b242eaffc13bff6b4373249ccb4466ff1d4eda1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
